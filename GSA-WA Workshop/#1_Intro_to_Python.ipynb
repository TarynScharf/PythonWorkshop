{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTjUkLJq20je"
   },
   "source": [
    "## Welcome to the CFIGS Python for Geosciences Workshop!\n",
    "### Who are we?\n",
    "\n",
    "#### Piero Sampaio (PhD Student - Curtin)\n",
    "I did my undergraduate and MSc. in the Federal University of Rio de Janeiro (UFRJ), where I was born and raised. My research is in geochemistry and igneous petrology, more specifically, I use isotopic signatures from ophiolites to try to understand how Earth's mantle composition evolved since the Neoproterozoic. I use Python on a daily basis to process my data, perform advanced data analysis and generate good-looking visuals.\n",
    "\n",
    "#### Dr. Taryn Scharf (Postdoctoral Researcher - Curtin)\n",
    "I am a postdoctoral researcher in the Timescales of Mineral Systems Group, Curtin University (https://research.curtin.edu.au/scieng/research/timescales-of-mineral-systems/). I am involved in developing computational tools that can be integrated with standard geological approaches for mineral analysis. My toolkit includes machine learning (tabular and image data sets), data analytics, and a variety of coding languages. Python is my preferred programming language for scientific data analysis.  I completed my PhD in Applied Geoscience in 2024 at Curtin University. Prior to my PhD, I spent 7 years as a geologist in the mining industry of South Africa. I was initially involved with brown fields exploration, geostatistical resource estimation, and the development of custom scripted solutions for clients. I later gained exposure to mine design, mine scheduling, and requirements analysis for software development.\n",
    "\n",
    "#### Dr. Luc Doucet (Senior Research Fellow - Curtin)\n",
    "Co-leader of the Earth Dynamics Research Group (http://geodynamics.curtin.edu.au/), I come from Bourg-en-Bresse, a small town in France famously known for its blue-white-red tricoloured (delicious) chickens. After a PhD in St Etienne, France (2012), I was awarded a three years fellowship from the Belgium Fund for Scientific Research to apply the \"non-traditional\" stable-isotope systematics to study the formation of both oceanic and continental lithosphere. After a two-year academic career break (being a stay-at-home dad), I moved to Curtin University in March 2018 to join the Earth Dynamics Research Group to decipher the present-day and past connections between Earth's mantle, supercontinent and superocean cycles. In 2023, I was awarded an ARC Future Fellowship to study the link between the deep carbon cycle with critical mineral deposits.\n",
    "\n",
    "### The notebok environment\n",
    "We'll be using Python notehooks to introduce you to the wonderful world of coding. Notebooks are handy ways to run short bits of code (in this case Python) and view results, without having to run a full program or script. This is ideal for practicing short examples or performing small pieces of analytics.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6xEJ2q58Zbf"
   },
   "source": [
    "## (Very) simple math\n",
    "Python has a series of in-built mathematical operators.\n",
    "* Addition: + \n",
    "* Subtraction: _\n",
    "* Multiplication: *\n",
    "* Division: /\n",
    "* Modulus: %\n",
    "* Exponentiation: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1 #Addition: +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2-1 #Substraction: -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*3 #Multiplication: *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3/3 #Division: /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26%8 #Modulus: %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**3 #Exponentiation: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbgLKK_T7hdr"
   },
   "source": [
    " ## Variables\n",
    "We can assign values to variables, which will store the value and make it easier to work with no matter the data type. Data types determine how the data behaves and what we can do to it. Examples of data typyes are:\n",
    "\n",
    "- int: integer numbers\n",
    "- float: numbers with decimal values\n",
    "- str: text - strings of characters\n",
    "- bool: True/False values\n",
    "\n",
    "We can also have composite data types that store collections of data. Python has 4 built-in composite data types:\n",
    "\n",
    "- list: mutable (can be changed) object that contains other values\n",
    "- tuple: same, but immutable (cannot be changed)\n",
    "- dict: key-value pairs\n",
    "- set: like a list but only contains unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_integer = 42 # integer number\n",
    "my_string = \"Python\" # string (text)\n",
    "my_float = 4.56 # float (decimal values or fractional numbers)\n",
    "my_boolean = True # boolean value (condition that be True or False)\n",
    "my_list = [\"a\",23,399.8,False] # Although a list can hold multiple variable types, it makes more sense to make a list of the SAME variable type). Note the square brackets\n",
    "my_dictionary = {\n",
    "    \"str\":\"a\",\n",
    "    \"int\":23,\n",
    "    \"float\":399.8,\n",
    "    \"bool\":False\n",
    "} # a dictionary is made of key: value pairs. Keys are always strings values. \n",
    "#Note the curly brackets\n",
    "my_tuple = (3,4,5) #tuples are delcared with round brackets\n",
    "my_set = {3,4,5} or my_set = set([3,4,5]) # sets are declared with curly brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the **data type**, different actions can be performed on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_integer = 42 \n",
    "print(my_integer + 5)\n",
    "\n",
    "my_float = 4.568 \n",
    "print(round(my_float,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strings are alphanumeric. You can manipulate strings extensively in Python\n",
    "my_string = 'Hello world'\n",
    "print(f' Original string: {my_string}')\n",
    "\n",
    "replacement = my_string.replace(' ', '_')\n",
    "print(f'\\n Replacement: {replacement}')\n",
    "\n",
    "uppercase = my_string.upper()\n",
    "print(f'\\n Capitalise: {uppercase}')\n",
    "\n",
    "substring = my_string[0:5]\n",
    "print(f'\\n Substring: {substring}') \n",
    "\n",
    "multiply = my_string * 3\n",
    "print(f'\\n Mutiplication: {multiply}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of numbers. Note the square brackets.\n",
    "my_list = [2,5,3,8,5] \n",
    "\n",
    "my_list.append(100) #you can add to a list\n",
    "print(my_list)\n",
    "\n",
    "print(my_list[3]) # you can get items out of a list using their positional index\n",
    "\n",
    "my_list[3]='999' #you can change the values of items in a list\n",
    "print(my_list)\n",
    "\n",
    "list_length = len(my_list) #You can query the length of composite data types like lists\n",
    "print(f'There are {list_length}  items in my_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>TRY IT YOURSELF:</b> \n",
    "<ol style=\"color: green\";\">\n",
    "<li>Print out the depth of drillhole ANT002</li>\n",
    " <li>Append 5 to list_1 and print the updated list</li>\n",
    " <li>Try add  3 and then 6 to my_set like this: my_set.add(3). Print out the updated set. What do you notice? </li>\n",
    "<li>Multiply list_1 by the 2nd number of list_1. Find find the length of the resultant list using len(). </li>\n",
    "</ol>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - Print out the depth of drillhole ANT002.\n",
    "#HINT: drillhole_depths[key]\n",
    "\n",
    "drillhole_depths = {\n",
    "    \"ANT001\":755.7,\n",
    "    \"ANT002\":624.7,\n",
    "    \"ANT003\":342.7\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Append 5 to list_1 and print the updated list\n",
    "# HINT: list_1.append(...)\n",
    "\n",
    "list_1 = [2,4,7,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Try add 3 and then 6 to my_set like this: my_set.add(3). \n",
    "#Print out the updated set. What do you notice?\n",
    "#HINT: my_set.add(....) OR my_set.update((3,6))\n",
    "my_set = {3,4,5} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Multiply list_1 by the 2nd number of list_1. \n",
    "#Find find the length of the resultant list using len().\n",
    "#Type your code here: len(list_1 * list_1[index]) \n",
    "\n",
    "list_1 = [2,4,7,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6lkGrcw8FT5"
   },
   "source": [
    "## Functions\n",
    "A function is a piece of code that performs an action. Code is often broken up into a series of functions, each performing a specific task. \n",
    "\n",
    "* In Python we declare functions using the `def` keyword at the beginning of the line. \n",
    "* All code that forms part of the function is placed on the next **indentation** level. Each indentation is performed by pressing the tab key. \n",
    "* We can press shift + tab to go back to the previous indentation\n",
    "* We can use a function when we call it by name. \n",
    "\n",
    "The classic introduction to any programming language is the hello world function. We will also use the print function, which prints (😲) something to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1723103166110,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "JDVQb449_2gl",
    "outputId": "e1f6c136-c063-466e-a03f-dc75344211e5"
   },
   "outputs": [],
   "source": [
    "def hello_world(): #def define the function hello_world. You can name your function anything you like, but it's best to make it sensible\n",
    "  print(\"hello world!\") # the function print hello world\n",
    "\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1723847475807,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "ZE0mynVSABqb",
    "outputId": "06257d18-3dcd-4a3f-9781-3a653a3e594d"
   },
   "outputs": [],
   "source": [
    "def addition(a,b): \n",
    "  c = a + b\n",
    "  return c \n",
    "\n",
    "addition_result = addition(3,4) \n",
    "print(addition_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"green\"><b>TRY IT YOURSELF:</b> Create a function that calculates the average of 3 numbers and prints the result. Use variables so that the 3 inputs can be changed by the user without having to change the code inside the function.</font>  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP5cKlV6VToU"
   },
   "source": [
    "# Loops\n",
    "If we want to repeat an action multiple times, sometimes changing only a few factors, we can use a loop to automate that action. Loops come in two flavours:\n",
    "`for` and `while` loops.\n",
    "## `For` loop:\n",
    "A `for` loop repeats an action for every object in a given group (list, dict, array, etc). The loop will be performed for all code that is within the next **indentation** level. Each indentation is performed by pressing the `tab` key. We can press `shift` + `tab` to go back to the previous indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kppht9xLZvG6"
   },
   "outputs": [],
   "source": [
    "# different indentation levels\n",
    "a\n",
    "  b\n",
    "    c\n",
    "      d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop example:\n",
    "\n",
    "file_names = ['ANT001_COLLAR.csv', 'Ant001_stratigraphy.csv', 'ANT002_COLLAR.csv', 'ant002_assay.csv', 'aNT003_COLLAR'] \n",
    "\n",
    "unique_drillhole_ids = set()\n",
    "\n",
    "for file in file_names:\n",
    "    file = file.lower()\n",
    "    drillhole_id = file.split(\"_\")[0] \n",
    "    unique_drillhole_ids.add(drillhole_id) #\n",
    "\n",
    "print(f'There are {len(unique_drillhole_ids)} drillholes.')\n",
    "print(f'Unique drillhole IDs: {unique_drillhole_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"green\"><b>TRY IT YOURSELF:</b> Two dictionaries are provided. One is total drillhole depth, the other is rc precollar depth. Use a for-loop to loop through all drillholes and calculate the total diamond drill depth by substracting the precollar depth from the total depth.</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drillhole_total_depths = {\n",
    "    \"ANT001\":755.7,\n",
    "    \"ANT002\":624.7,\n",
    "    \"ANT003\":342.7,\n",
    "    \"ANT004\": 150\n",
    "} \n",
    "\n",
    "drillhole_rc_precollar_depth = {\n",
    "    \"ANT001\":104.7,\n",
    "    \"ANT002\":117,\n",
    "    \"ANT003\":104.7,\n",
    "    \"ANT004\": 141\n",
    "    \n",
    "}\n",
    "#Hint: you can get a list of dictionary keys as follows: drillhole_ids = list(drillhole_total_depths.keys())\n",
    "#Use a for-loop to loop through all IDS in drillhole_ids\n",
    "# Use the id's as dictionary keys to get total depth and rc depth per drillhole\n",
    "# Subtract precollar depth from total depth (inside the for-loop)\n",
    "# Print the key value and total diamond drill depth calculated (inside the for-loop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `While` loop:\n",
    "A `while` loop repeats an action while a condition is `True`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#While loop example\n",
    "drill_depth_in_meters = [0, 1.5, 2.2, 3.5, 4.6, 5.8, 6.6, 7.4, 8.6, 9.7, 10.6]\n",
    "\n",
    "length_drilled = 0\n",
    "i=0\n",
    "\n",
    "while length_drilled <7:\n",
    "    length_drilled = length_drilled + drill_depth_in_meters[i]\n",
    "    print(f'{length_drilled} meteres drilled after {i+1} iterations') \n",
    "    i =i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"green\"><b>TRY IT YOURSELF:</b> A counter has been provided.  While the counter is less than 10, increment its value by 2 and print out the counter. </font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NwBOqO3an_2"
   },
   "source": [
    "# Conditionals and control\n",
    "Conditionals in Python, like in many other programming languages, allow you to make decisions in your code. They help your programs to behave differently based on certain conditions. In Python, you use if, elif (else if), and else statements to create conditionals.\n",
    "\n",
    "1. if Statements:\n",
    "The if statement is used to execute a block of code if a condition is true.\n",
    "\n",
    "2. elif Statements:\n",
    "elif is short for \"else if\". It allows you to check multiple conditions. If the first if condition is false, it checks the next elif condition, and so on.\n",
    "\n",
    "3. else Statements:\n",
    "The else statement is used to execute a block of code if none of the conditions in the if and elif statements are true.\n",
    "\n",
    "4. Nesting Conditionals:\n",
    "You can also nest conditionals inside each other to handle more complex situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoQUtCKPanIg"
   },
   "outputs": [],
   "source": [
    "# if statement:\n",
    "num = 15\n",
    "if num % 2 == 0:\n",
    "    print(\"Even\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1723848238144,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "C2WqOLzgbc9O",
    "outputId": "2b455644-23ea-4885-de81-65d079144ce2"
   },
   "outputs": [],
   "source": [
    "# else statement\n",
    "num = 15\n",
    "if num % 2 == 0:\n",
    "    print(\"Even\")\n",
    "else:\n",
    "    print(\"Odd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1723848213707,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "Bvgd8HMSbaw0",
    "outputId": "59e4fc36-8842-41ab-e91b-6ea9d31bfd13"
   },
   "outputs": [],
   "source": [
    "# elif statement:\n",
    "average_grams_per_tonne = 7.85\n",
    "if average_grams_per_tonne >= 10:\n",
    "    print(\"High grade\")\n",
    "elif average_grams_per_tonne >= 5:\n",
    "    print(\"Medium grade\")\n",
    "elif average_grams_per_tonne>=1:\n",
    "    print(\"Low grade\")\n",
    "else:\n",
    "    print('Subeconomic')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoyoq6_XcUJO"
   },
   "source": [
    "## We can mix loops and conditionals to make more complex actions\n",
    "Have you ever inhereted a messy  folder of project data? Let's standardise file names in the Antrim_Data folder provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1723103501617,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "QSIubGPLb-Ce",
    "outputId": "5dbaefe5-3437-4e07-9f41-7fbbec65cb2a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'Antrim_data'\n",
    "\n",
    "#get a list of everything in the folder\n",
    "folder_contents = os.listdir(folder_path)\n",
    "\n",
    "#loop through every item in the list\n",
    "for item in folder_contents:\n",
    "\n",
    "    #if the item is not an excel file (e.g. it's an image), continue looping (ignore the item)\n",
    "    if 'xlsx' not in  item:\n",
    "        continue #skip the rest of the iteration and jump to the next loop iteration\n",
    "\n",
    "    #create new file names\n",
    "    item_name = item.lower()\n",
    "    if \"majors\" in item_name:\n",
    "        new_item_name = \"antrim_assay_major_elements.xlsx\"\n",
    "    elif \"traces\" in item_name:\n",
    "        new_item_name = \"antrim_assay_trace_elements.xlsx\"\n",
    "    elif \"collar\" in item_name:\n",
    "        new_item_name = \"antrim_collars.xlsx\"\n",
    "    elif \"geology\" in item_name:\n",
    "        new_item_name = \"antrim_stratigraphy.xlsx\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    old_path = os.path.join(folder_path, item)\n",
    "    new_path = os.path.join(folder_path, new_item_name)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed: {item} to {new_item_name}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"green\"><b>TRY IT YOURSELF:</b> Let's loop through the contents of the Antrim folder and separate Excel and image files into their own folders. Follow the instructions below. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "# create a variable to hold the Antrim_data folder path (see above example)\n",
    "\n",
    "#create two new folders, one for excel and one for image files\n",
    "#e.g. excel_data_folder = os.path.join(folder_path, 'drillhole_data')\n",
    "\n",
    "#To not overwrite a folder, first we test to see if it already exists. We only create the new folder if it DOESN'T already exist\n",
    "#E.g. if not os.path.exists(excel_data_folder):\n",
    "        #os.makedirs(excel_data_folder)\n",
    "\n",
    "#Get a list of everything in the folder. See above for example.\n",
    "\n",
    "#loop through every item in the list\n",
    "# for ... in ...:\n",
    "    \n",
    "#If the item is a folder, continue looping (ignore the item)\n",
    "    #E.g. if os.path.isdir(os.path.join(folder_path,item)):\n",
    "        #continue\n",
    "    #If it's not a folder, get the file extension\n",
    "    #E.g. file_extension = os.path.splitext(file)[-1]\n",
    "\n",
    "    #If it's an excel file, move it into the excel folder\n",
    "    #if file_extension == '.xlsx':\n",
    "        #old_file_path = os.path.join(folder_path, file)\n",
    "        #new_file_path = os.path.join(excel_data_folder, file)\n",
    "        #os.replace(old_file_path, new_file_path)\n",
    "\n",
    "    #Repeat to find .jpg files and move them to the image folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example solution\n",
    "import os\n",
    "\n",
    "folder_path = 'Antrim_data'\n",
    "\n",
    "#create two new folders, one for excel and one for image files\n",
    "excel_data_folder = os.path.join(folder_path, 'drillhole_data')\n",
    "image_data_folder = os.path.join(folder_path, 'drillhole_images')\n",
    "\n",
    "#To not overwrite a folder, first we test to see if it already exists\n",
    "#We only create the new folder if it DOESN'T already exist\n",
    "if not os.path.exists(excel_data_folder):\n",
    "        os.makedirs(excel_data_folder)\n",
    "\n",
    "if not os.path.exists(image_data_folder):\n",
    "        os.makedirs(image_data_folder)\n",
    "\n",
    "#get a list of everything in the folder\n",
    "folder_contents = os.listdir(folder_path)\n",
    "\n",
    "#loop through every item in the list\n",
    "for item in folder_contents:\n",
    "\n",
    "    #if the item is a folder, continue looping (ignore the item)\n",
    "    if os.path.isdir(os.path.join(folder_path,item)):\n",
    "        continue\n",
    "    \n",
    "    file_extension = os.path.splitext(item)[-1]\n",
    "\n",
    "    if file_extension == '.xlsx':\n",
    "        old_file_path = os.path.join(folder_path, item)\n",
    "        new_file_path = os.path.join(excel_data_folder, item)\n",
    "        os.replace(old_file_path, new_file_path)\n",
    "        \n",
    "    if file_extension == '.jpg':\n",
    "        old_file_path = os.path.join(folder_path, item)\n",
    "        new_file_path = os.path.join(image_data_folder, item)\n",
    "        os.replace(old_file_path, new_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Epx8JQcy_vj6"
   },
   "source": [
    "# The true power of Python: Libraries (or modules)\n",
    "Python goes way beyond by using different libraries. Libraries extend the functionality of Python. There are some built-in Python libraries (e.g. math), but there are heaps of user-created libraries. Whenever you want to do something on Python, chances are that someone has already created a library to make your life easier. First, we must import the desired library using the `import` statement. Generally, imports are in the first part of the code.\n",
    "\n",
    "Examples of built-in libraries are `math`, `os`, `time`,`stats`, etc\n",
    "\n",
    "The `math` library, for example, has many useful mathematical functions already implemented. Once we import the library we can access the functions in the library by using the `.` after the name of the library:\n",
    "`math.cos()` would give you the cosine function. Certain libraries also have attributes which can be accessed in the same way, such as `math.pi`. Note that this is not a function, so it does not need the parentheses after it.\n",
    "\n",
    "We have already used the `os` library to help us organise the drillhole datafiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1723848702794,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "VUxKPC2W_pzU",
    "outputId": "2937e65c-fb65-499c-d582-896419385c0f"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "c = math.cos(math.pi) # we use the dot to access the cosine function\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHZu6eMo6bEk"
   },
   "source": [
    "We can also import only certain functions of a library. In that case we do not need to use the `math.cos()` anymore, we can call the function directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1723103562881,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "HkgxHVYBvrut",
    "outputId": "549c510b-d35c-4f01-b26b-2d6649b55aeb"
   },
   "outputs": [],
   "source": [
    "from math import cos\n",
    "c = cos(math.pi)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfaS6BJMwhZU"
   },
   "source": [
    "Finally, we can also import a library with an alias that will be used throughout the code. For the `math` library that doesn't really matter but for libraries with longer names (classic example would be `matplotlib.pyplot`) it is useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZayDi_MxKb0"
   },
   "source": [
    "## External libraries\n",
    "\n",
    "These libraries, created and shared by the global Python community, cater to diverse needs such as data analysis, web development, machine learning, and more. For instance, the Pandas library simplifies data manipulation and analysis through its powerful data structures, the Matplotlib library enables high-quality data visualization and numpy for numerical calculations. These libraries expand Python's capabilities dramatically, allowing developers to leverage pre-built solutions and focus more on problem-solving rather than reinventing the wheel.\n",
    "\n",
    "In this workshop, we`ll be using mostly external libraries and applying them to geology related problems. The main libraries we'll use are:\n",
    "- [numpy](https://numpy.org/)\n",
    "- [scipy](https://scipy.org/)\n",
    "- [matplotlib](https://matplotlib.org/)\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [geopandas](https://geopandas.org/en/stable/)\n",
    "- [seaborn](https://seaborn.pydata.org/)\n",
    "- [pyrolite](https://pyrolite.readthedocs.io/en/main/) (developed by Morgan Williams of CSIRO)\n",
    "- [PyGMT](https://www.pygmt.org/latest/index.html) (maintained by a group of geophysicists in various places)\n",
    "\n",
    "For example the `numpy` library extends (a lot) the functionality of the `math` library. One use case is that `math` operates on single objects, whereas `numpy` operates on arrays (a type of group of objects) directly, which saves us from using loops all the time. This is great, because loops are very inefficient in terms of speed. It might not be vital for short tasks, but it scales very quickly.\n",
    "\n",
    "## Numpy\n",
    "This is your go-to for almost all numerical applications in Python. Fast, highly optimized library for working with arrays of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1723845290037,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "6GZX8d2k7Lx4",
    "outputId": "b5e87cc1-e36d-4af6-af69-844aadf68524"
   },
   "outputs": [],
   "source": [
    "# with math\n",
    "import math\n",
    "\n",
    "number_range = range(0,20,1) # built-in function to define a range of numbers: range(start number, number to stop before, increment)\n",
    "results = [] # create list to store results\n",
    "for i in number_range:\n",
    "  results.append(math.sqrt(i))\n",
    "print(results)\n",
    "\n",
    "# math only takes real numbers as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1723845309740,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "6_30bUC3xJFW",
    "outputId": "82047b7a-f115-4940-cf52-fec52ab37126"
   },
   "outputs": [],
   "source": [
    "# with numpy\n",
    "import numpy as np # common alias for numpy\n",
    "\n",
    "results = np.sqrt(number_range) # we can operate directly on the range object\n",
    "results # the object is returned as an array data type, which is the type on which numpy operates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1723845503987,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "7jeOS_QVyYcY",
    "outputId": "7102c87b-dcfa-43e4-fc8f-34eefae06de9"
   },
   "outputs": [],
   "source": [
    "# numpy also has its own version of the range function which automatically generates an array\n",
    "arr = np.arange(0,100,5) # np.arange(start, stop, step)\n",
    "arr2 = np.linspace(0,100,21) # (start, stop, num_intervals) \n",
    "print(f'array 1: {arr}')\n",
    "print(f'array 2: {arr2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1723845497804,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "0OGLVYq-0f7f",
    "outputId": "3d58b23a-172a-4f1e-c052-e5bc802b5322"
   },
   "outputs": [],
   "source": [
    "# We can access items in the array by using indexes (positional number in the list).\n",
    "# Keep in mind that Python starts counting from 0.\n",
    "arr = np.arange(0,100,5) # start, stop, step\n",
    "print(arr[2]) # returns the third item in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1723845460717,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "JaqPRPuf09WM",
    "outputId": "a4318720-a2a8-4ead-cf87-66616e223551"
   },
   "outputs": [],
   "source": [
    "print(arr2[-1]) # -1 is a shortcut for last item in the array. We can count backwards from -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1723845495989,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "i9ILgIJv1ONX",
    "outputId": "dbf03e85-046e-4542-a128-a9be126bb4c4"
   },
   "outputs": [],
   "source": [
    "# we can also index with slices\n",
    "# [start:stop] where stop is not inclusive\n",
    "print(arr[0:5]) # first five items of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1723845625685,
     "user": {
      "displayName": "T S",
      "userId": "01569976147042665237"
     },
     "user_tz": -480
    },
    "id": "HVEHM-DL1c5R",
    "outputId": "34a0ee00-72e1-4f7b-bfef-1866d3bbb564"
   },
   "outputs": [],
   "source": [
    "# And finally this works for multidimensional arrays as well\n",
    "# The dimensions are separated by commas, so notation is similar to that of a matrix\n",
    "# Arrays also don't need to be 1d, they can have multiple dimensions. For example, here we reshape our 20-number arrange into a 2D matrix that has 2 rows and 10 columns:\n",
    "arr_2d = arr.reshape(2,10)\n",
    "print(arr_2d)\n",
    "print(f'slice through array 2d:\\n {arr_2d[:,4:6]}') # returns the item in the fifth column of the first line (remember we count from 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a popular open-source data analysis and manipulation library for Python. It provides powerful data structures like DataFrame, which allows users to work with structured data seamlessly. One of Pandas' key strengths lies in its ability to read data from multiple formats, such as CSV, Excel, SQL databases, and more. This flexibility simplifies the process of importing and handling data, regardless of its source, making it a go-to choice for data scientists and analysts.\n",
    "\n",
    "Reading Data from Multiple Formats\n",
    "\n",
    "Pandas simplifies the data import process. For instance, to read a CSV file into a DataFrame, you can use the pd.read_csv('filename.csv') function. Similarly, Pandas supports pd.read_excel(), pd.read_sql(), and various other functions tailored to specific data formats. This versatility streamlines the data preprocessing phase, allowing analysts to focus on extracting insights rather than dealing with data intricacies.\n",
    "\n",
    "Filtering Capabilities\n",
    "\n",
    "Pandas excels at data filtering, enabling users to extract specific subsets of data efficiently. Through techniques like boolean indexing and query operations, users can filter data based on conditions. For instance, df[df['column_name'] > threshold] filters rows where the 'column_name' values exceed a defined threshold. This functionality allows users to explore and analyze specific segments of their data easily.\n",
    "\n",
    "Applications in Geology\n",
    "\n",
    "Geologists often deal with extensive datasets containing information about rock compositions, mineral compositions, structural data, spectral data, stratigraphy, and more. Pandas' ability to handle large datasets and its filtering capabilities are invaluable in such scenarios. Geologists can use Pandas to filter seismic data based on specific time frames, analyze mineral compositions, or explore geological features based on various parameters. Furthermore, Pandas seamlessly integrates with visualization libraries like Matplotlib and Seaborn, enabling geologists to create insightful charts and plots for better data interpretation.\n",
    "\n",
    "In summary, Pandas in Python offers a robust and versatile framework for data analysis and manipulation. By harnessing Pandas' capabilities, geologists can enhance their data-driven decision-making processes and gain deeper insights into geological phenomena. \n",
    "\n",
    "In pandas the datasets are stored as pandas.DataFrame objects if 2D or as pandas.Seriesobjects if 1D (vector). One advantage of pandas for handling tabular data and data analysis compared to numpy is that we can access columns by their names instead of having to memorize indexes.\n",
    "\n",
    "In an object-oriented framework such as Python, objects can have associated methods and attributes. This was already the case for numpy, but is also key in the pandas DataFrameand Series objects.\n",
    "\n",
    "A method is like a function specific for an object. Once we have an object of a certain class instantiated (which just means we declared a variable of a certain class), we can call methods for that objects. We call a method by using object.method()notation. Sometimes methods take arguments, just like functions.\n",
    "\n",
    "An attribute is a static property of the object. So instead of being called by placing parentheses after the name, we just use object.attribute to visualize the attributes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's read the Antrim major element data, skipping unwanted rows\n",
    "\n",
    "#But first, a bit of house-keeping to help us view all the table columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#Now read in the data file\n",
    "majors_df = pd.read_excel('Antrim_data/drillhole_data/antrim_assay_major_elements.xlsx', header=1, skiprows=[2, 3, 4, 5])\n",
    "majors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic dataframe commands:** \n",
    "Pandas is filled with useful functionality to manipulate tabular data. <br>\n",
    "Here are a few to know, to complete the following exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of the column names:\n",
    "majors_df.columns # .values turns this into an array object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Access columns by name: \n",
    "majors_df['Interval'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select specific rows and/or columns using lable location\n",
    "majors_df.loc[0:3, ['Location', 'Interval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select specific rows and/or columns using integer location\n",
    "majors_df.iloc[0:3, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column: majors_df['New_column'] = np.NAN\n",
    "majors_df['New_column'] = np.nan\n",
    "majors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use columns in calculations: \n",
    "majors_df['New_calculation'] = majors_df['LOI']*100\n",
    "majors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove columns and/or rows:\n",
    "majors_df.drop(['New_column','New_calculation'], axis=1, inplace=True) #axis = 0 means rows\n",
    "majors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter a dataframe for particular values\n",
    "filtered_df = majors_df[majors_df['Location']=='ANT001']\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframe manipulation:**\n",
    "Now that we know some essential commands, let's clean up our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's rename the sample id  and drillhole id column:\n",
    "majors_df.rename(columns={majors_df.columns[0]: \"sampleid\", 'Location':'hole' }, inplace=True)\n",
    "majors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some below-detection values ('<') in the SO3 column, rows 17-19. \n",
    "#Let's take a look at them:\n",
    "majors_df.loc[17:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's change all '<' values in the data from to to 0.005\n",
    "\n",
    "#We'll use slicing to get the major element columns that we want:\n",
    "major_elements = majors_df.columns[3:]\n",
    "\n",
    "#Let's assign a value of 0.005\n",
    "majors_df[major_elements] = majors_df[major_elements].replace('<', 0.005)\n",
    "\n",
    "#Display the updated rows\n",
    "majors_df.loc[17:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finger-errors are common. Sometimes we end up with text in our numeric fields\n",
    "#E.g. SO3 column\n",
    "majors_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's loop through all the columns and make non-numeric data NAN\n",
    "for column in major_elements:\n",
    "    majors_df[column] = pd.to_numeric(majors_df[column], errors='coerce')\n",
    "majors_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remove any duplicate values in the dataframe\n",
    "majors_df.drop_duplicates(subset=majors_df.columns[2:],keep='first', inplace= True, ignore_index = True)\n",
    "majors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's update our new assay table to contain From and To columns instead of an Interval column\n",
    "#We will remove the interval column\n",
    "majors_df['From'] = majors_df['Interval'].str.split('-').str[0]\n",
    "majors_df['To'] = majors_df['Interval'].str.split('-').str[1]\n",
    "majors_df.drop('Interval',axis = 1, inplace = True)\n",
    "majors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have:\n",
    "- Read in the data from excel\n",
    "- Replaced '<' with 0.005\n",
    "- Removed accidental text in numeric columns\n",
    "- Removed duplicated rows\n",
    "- Created new From and To columns\n",
    "- Remove unwanted columns ('Interval')\n",
    "\n",
    "We would need to repeat all this code for the table containing trace elements. Instead, let's create a function that will do all this data processing on each assay file we give it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_assay_data(file_path, header_row, rows_to_skip):\n",
    "    dataframe = pd.read_excel(file_path, header=header_row, skiprows=rows_to_skip)\n",
    "\n",
    "    assay_columns = dataframe.columns[3:]\n",
    "    dataframe[assay_columns] = dataframe[assay_columns].replace('<', 0.005)\n",
    "    \n",
    "    for column in assay_columns:\n",
    "        dataframe[column] = pd.to_numeric(dataframe[column], errors='coerce')\n",
    "\n",
    "    dataframe.drop_duplicates(inplace= True, ignore_index = True)\n",
    "\n",
    "    dataframe['From'] = dataframe['Interval'].str.split('-').str[0]\n",
    "    dataframe['To'] = dataframe['Interval'].str.split('-').str[1]\n",
    "    dataframe.drop('Interval',axis = 1, inplace = True)\n",
    "\n",
    "    dataframe.rename(columns={dataframe.columns[0]: \"sampleid\", 'Location':'hole' }, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "major_elements = process_assay_data('Antrim_data/drillhole_data/antrim_assay_major_elements.xls', 1, [2, 3, 4, 5])\n",
    "trace_elements = process_assay_data('Antrim_data/drillhole_data/antrim_assay_trace_elements.xls', 0, [1,2, 3, 4, 5])   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_elements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are standards in our trace element data. <br> Lets remove them from the assay table and set them aside for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards = trace_elements[trace_elements['hole']=='STANDARD']\n",
    "trace_elements = trace_elements[trace_elements['hole'] != 'STANDARD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_elements.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's merge the major and trace element assay into one file, and save the file\n",
    "merged_assay_df = pd.merge(major_elements, trace_elements, on=['hole','sampleid', 'From', 'To'])\n",
    "merged_assay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save our new assay table to a csv file, which can be imported into any software.\n",
    "merged_assay_df.to_csv('Antrim_data/drillhole_data/Antrim_assay_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do some very basic comparisons of the values in our boreholes\n",
    "average_per_drillhole = merged_assay_df.groupby('hole').mean(numeric_only=True).round(2)\n",
    "average_per_drillhole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASamCBYa27e3"
   },
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is a powerful plotting library. We will use it a lot to graph data and show images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5JFUqE9101j"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot MgO vs Ni for drillhole ANT001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out data for ant001:\n",
    "ant001 = merged_assay_df[merged_assay_df['hole']=='ANT001']\n",
    "\n",
    "# create a figure, you can adjust the numbers (10, 6) to your desired width and height\n",
    "plt.figure(figsize=(6, 4)) \n",
    "\n",
    "# Creating the scatter plot\n",
    "plt.scatter(ant001['MgO'], # what's on the x-axis\n",
    "         ant001['Ni'], # what's on the y-axis\n",
    "         ) \n",
    "\n",
    "#Finishing touches\n",
    "plt.xlabel(\"MgO (%)\") # give label to your x axis\n",
    "plt.ylabel(\"Ni (ppm)\") # give label to your y axis\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <font color=\"green\"><b>TRY IT YOURSELF:</b> Using the ant001 data we just filtered out, plot Cu vs MgO </font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to customise your Matplotlib charts. Here we plot two series on one chart and customise the chart appearance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #get a list of drillhole ID's to loop through\n",
    "drillholes = merged_assay_df['hole'].unique()\n",
    "\n",
    "# create the figure OUTSIDE of the loop. We only need to create it ONCE\n",
    "plt.figure(figsize=(6, 4))  \n",
    "\n",
    "#inside the loop, do your plotting\n",
    "for hole_id in drillholes:\n",
    "    data = merged_assay_df[merged_assay_df['hole'] == hole_id] #filter out the data you want\n",
    "    plt.scatter(data['MgO'], # what's on the x-axis\n",
    "         data['Ni'], # what's on the y-axis\n",
    "         marker=\"s\", # marker style\n",
    "         alpha =0.5, #transparency\n",
    "         s = 50,   #marker size   \n",
    "         label=hole_id) # label for the legend\n",
    "\n",
    "#Outside the loop, apply your finishing touches\n",
    "plt.legend(title=\"Dillhole ID\") # place a legend\n",
    "plt.title(\"MgO vs Ni in Drillhole ANT001\")\n",
    "plt.xlabel(\"MgO (%)\") \n",
    "plt.ylabel(\"Ni (ppm)\") \n",
    "plt.show()\n",
    "plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run each of these cells and fix the errors that pop up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(os.path.join(folder_path,item):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list(range(2,7))\n",
    "print(f'my list contains {len(my_list)} items: {my_list}')\n",
    "my_list_item = my_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_value = 10.5\n",
    "print (grades_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "print(i+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antrim_drillhole_names = 'ant1'\n",
    "Antrim_drillhole_names.append('ant2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 9\n",
    "y = 'eight'\n",
    "\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(9 * 'eight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antrim_collar_coordinates = {\n",
    "    'ANT001': [572022, 7978167],\n",
    "    'ANT002': [564818,7995173]\n",
    "    }\n",
    "\n",
    "print(Antrim_collar_coordinates['ANT003'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Am I supposed to remember all this syntax?\n",
    "No. You're a geoscientist not a programmer! You should have awareness of **what is possible**. You can always look up syntax online. If you're trying to do something you've never done before, simply google it. There will be a lot of online help to guide you through your question.\n",
    "\n",
    "### Where do I find help if I'm trying to code on my own?\n",
    "- Online community forums e.g. Stack exchange (highly recommended - if  you have a question, it's probably been asked on stack exchange already)\n",
    "- Free learning websites e.g. Geeksforgeeks - great if you want a quick, clean example of  how to use a particular command.\n",
    "- Python modules  have documentation and tutorials online. There are important resources when you need to understand the specifics of any command you are running.\n",
    "- Many Python courses are available online. Often, they will be paid courses, but some allow you to 'audit' the course for free.\n",
    "### Why learn python if I can ask ChatGPT, Gemini etc.?\n",
    "Generative AI can be extremely useful when coding. E.g.\n",
    "- It can help you create data processing pipelines from plain-text prompts, especially when you're not sure exactly how to do it.\n",
    "- It can help with debugging, especially when you don't understand what's going wrong.\n",
    "- It can provide you the syntax for every-day commands when you can't remember them.\n",
    "\n",
    "However, despite appearing intelligent, **it is only a machine**. There are two important reasons to be python-literate:\n",
    "- Generative AI often makes mistakes and if you are not Python-literate, these can be hard to spot. **Generative AI is powerful but we strongly recommend developing Python-literacy so you can guard against errors.**  Just because the code works,  doesn't mean it's doing what you want!  However, if your company allows, it's a valuable tool to save you time and help you learn. Remember not to put **sensitive information** into the model, as inputs are used for training the model further. \n",
    "- The more specialised your needs, the less likely ChatGPT will be able to help. If you're python-literate, you can build on the feedback from sources like ChatGPT and StackExchange to meet your own unique needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
